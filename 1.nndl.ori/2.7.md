# 2.7 计算图

> 视频：<https://mooc.study.163.com/learn/deeplearning_ai-2001281002?tid=2001392029#/learn/content?type=detail&id=2001701011>

可以说，一个神经网络的计算，都是按照前向或反向传播过程来实现的。首先计算出神经网络的输出，紧接着进行一个反向传输操作。后者我们用来计算出对应的梯度或者导数，这个流程图解释了，为什么用这样的方式实现。

在这个视频中，我们将看一个例子，为了阐明这个计算过程，举一个比 logistic 回归更加简单的、不那么正式的神经网络的例子。我们尝试计算函数`J`，`J`是三个变量`a b c`的函数，这个函数是`3(a+b*c)`。

![](img/2-7-1.jpg)

计算这个函数，实际上有三个不同的步骤，首先是计算`b`乘以`c`。我们把它储存在变量`u`中，因此`u=b*c`。然后计算`v=a+u`，这就是`v`。最后输出`J`，就是`3*v`。这就是要计算的函数`J`。

![](img/2-7-2.jpg)

我们可以把这三步，画成如下的流程图。我先在这画三个变量`a b c`，第一步就是计算`u=b*c`，我在这周围放个矩形框。它的输入是`b`和`c`，接着第二步`v=a+u`，这个的输入就是刚才计算出来的`u`还有`a`。最后一步`J=3*v`。举个例子`a=5 b=3 c=2`，`u=bc`就是`6`，`v=a+u`就是`5+6=11`。`J`是三倍的`v`，因此 `J`就等于`33`。

你们自己可以验证一下。这是`3*(5+3*2)`。如果你把它算出来，实际上得到`33`，就是`J`的值。这个流程图用起来很方便，当存在一些不同或特殊的变量时，比如`J`也是我们想要优化的东西。

![](img/2-7-3.jpg)

在 logistic 回归中，`J`是想要最小化的成本函数。可以看出，通过一个从左向右的过程，你可以计算出`J`的值。在接下来的幻灯片中我们会看到，为了计算导数，从右到左的这个过程，和这个蓝色箭头的过程相反。这会是用于计算导数的，最自然的方式。

因此概括一下，流程图是用蓝色箭头画出来的，从左到右的计算。下一个视频中，我们看看这个反向红色箭头画的，也就是从右到左的导数计算，是怎么回事。让我们继续下一个视频。
