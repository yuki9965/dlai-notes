# 2.11 向量化

> 视频：<https://mooc.study.163.com/learn/deeplearning_ai-2001281002?tid=2001392029#/learn/content?type=detail&id=2001701013>

向量化是消除你的代码中的`for`循环的艺术。在深度学习中，代码的运行速度特别重要，否则当你处理较大的数据集时，你需要很长时间才能得到结果。所以代码的向量化就变成了一个关键的技巧。

所以让我们用一个例子开始。logistic 回归中，`z = w^Tx + b`，`w`和`x`都是`n`维向量。在非向量化的代码中，我们这样做：

```py
z = 0
for i in range(nx):
    z += w[i] * x[i]
z += b
```

然而在 NumPy 中，我们可以这样，它更快一些：

```py
z = np.dot(w.T, x) + b
```

然后我们在 jupyter notebook 中测量其速度。我们首先创建一个数组。

```py
import numpy as np
a = np.array([1,2,3,4])
print(a)
# [1 2 3 4]
```

然后我们随机创建两个个百万元素的一维数组，之后测量`np.dot`的效率。

```
import time

a = np.random.rand(1000000)
b = np.random.rand(1000000)

tic = time.time()
c = np.dot(a, b)
toc = time.time()
print("Vectorize version:" + str(1000*(toc-tic) + "ms")
# Vectorize version: 2.9833316802978516ms
```

所以这个代码仅仅花了三毫秒左右，平均好像要花费 1.5 毫秒。

这是非向量化的版本：

```py
c = 0
tic = time.time()
for i in range(1000000):
    c += a[i] * b[i]
toc = time.time()
print("For loop:" + str(1000*(toc-tic) + "ms")
# For loop: 474.29513931274414ms
```

显然，非向量化的版本花费了几乎 500 毫秒，300 倍于向量化版本。所以这个例子说明了，如果你使用向量化的版本，你的代码可以快 300 倍。

你可能听说，可扩展深度学习是运行在 GPU 上的。我这里的代码运行在 jupyter notebook 上，只利用了 CPU。CPU 和 GPU 都有并行化的指令，有时候叫做 SIMD 指令（单指令多数据流）。意思是，如果你使用这种 NumPy 内置函数，或者其它能让你去掉显式的`for`的函数，这样 NumPy 能充分利用并行化，来更快计算。
